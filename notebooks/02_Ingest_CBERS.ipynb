{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSIfBsgi8dNK"
      },
      "source": [
        "#@title Copyright 2024 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingest CBERS data from GCS\n",
        "\n",
        "This script lists a set of XML files from CBERS4A assets stored in a Cloud Storage bucket (here, a bucket named \"CBERS4A\"), then triggers image ingestion."
      ],
      "metadata": {
        "id": "zVyQAexqhq7A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmxat3ujhwGx"
      },
      "source": [
        "## Start an authorized session\n",
        "\n",
        "To be able to make an Earth Engine asset in your user folder, you need to be able to authenticate as yourself when you make the request.  You can use credentials from the Earth Engine authenticator to start an [`AuthorizedSession`](https://google-auth.readthedocs.io/en/master/reference/google.auth.transport.requests.html#google.auth.transport.requests.AuthorizedSession).  You can then use the `AuthorizedSession` to send requests to Earth Engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVu8GhINwYfO"
      },
      "source": [
        "import ee\n",
        "from google.auth.transport.requests import AuthorizedSession\n",
        "\n",
        "ee.Authenticate()  #  or !earthengine authenticate --auth_mode=gcloud\n",
        "\n",
        "# Specify the project you want associated with Earth Engine requests.\n",
        "ee_project = 'ee-demos' # @param {\"type\":\"string\",\"placeholder\":\"mdewitt-earthengine\"}\n",
        "\n",
        "session = AuthorizedSession(\n",
        "    ee.data.get_persistent_credentials().with_quota_project(ee_project)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a list of all the images from the bucket.\n",
        "\n",
        "This produces a list of all of the `BAND6.xml` files in the bucket; each image is assumed to correspond one-to-one with a `BAND6.xml` file."
      ],
      "metadata": {
        "id": "X3gtIo3IOhF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil ls -r gs://cbers4a-test/WFI/** | grep 'BAND14.xml' > xmlfiles.txt\n",
        "! wc -l xmlfiles.txt\n",
        "! head xmlfiles.txt"
      ],
      "metadata": {
        "id": "O_f0iLuEMqEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the path of an XML file, parse out the metadata."
      ],
      "metadata": {
        "id": "iEO3YTt1OqGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install untangle"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oMY3E3xaRYDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib.parse import urlparse\n",
        "from urllib.parse import urlunparse\n",
        "import pathlib\n",
        "import requests\n",
        "import untangle\n",
        "import urllib3\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Cloud Storage client.\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# The number of parallel threads to use for reading data and registering images.\n",
        "THREAD_COUNT = 40\n",
        "adapter = HTTPAdapter(\n",
        "    pool_connections=THREAD_COUNT*2,\n",
        "    pool_maxsize=THREAD_COUNT*2)\n",
        "storage_client._http.mount(\"gs://\", adapter)\n",
        "storage_client._http.mount(\"https://\", adapter)\n",
        "storage_client._http._auth_request.session.mount(\"https://\", adapter)\n",
        "session.mount(\"gs://\", adapter)\n",
        "session.mount(\"https://\", adapter)\n",
        "\n",
        "# Housekeeping - this is a noisy warning.\n",
        "warnings.filterwarnings('ignore', message=\".*Connection pool size.*\")\n",
        "\n",
        "def getMetadata(xmlUrl):\n",
        "  \"\"\"Return the metadata dict for the given URL.\"\"\"\n",
        "  parsed = urlparse(xmlUrl)\n",
        "  bucket = storage_client.bucket(parsed.netloc)\n",
        "  blob = bucket.blob(parsed.path.strip('/'))\n",
        "\n",
        "  with blob.open(\"r\") as f:\n",
        "    return extractMetadata(f.read())\n",
        "\n",
        "def extractMetadata(fileContents):\n",
        "  \"\"\"Extract the metadata dict from a file's contents.\"\"\"\n",
        "  # Metadata\n",
        "  m = untangle.parse(fileContents).prdf\n",
        "\n",
        "  # Properties\n",
        "  p = {}\n",
        "#  p['ORIENTATION_ANGLE_DEGREE'] = m.orientationAngle.degree.cdata\n",
        "#  p['ORIENTATION_ANGLE_MINUTE'] = m.orientationAngle.minute.cdata\n",
        "#  p['ORIENTATION_ANGLE_SECOND'] = m.orientationAngle.second.cdata\n",
        "#  p['SUN_INCIDENCE_ANGLE_DEGREE'] = m.sunIncidenceAngle.degree.cdata\n",
        "#  p['SUN_INCIDENCE_ANGLE_MINUTE'] = m.sunIncidenceAngle.minute.cdata\n",
        "#  p['SUN_INCIDENCE_ANGLE_SECOND'] = m.sunIncidenceAngle.second.cdata\n",
        "#  p['VIEWING_TIME_CENTER'] = m.viewing.center.cdata + 'Z'\n",
        "\n",
        "  m = m.image\n",
        "#  p['RECEIVING_STATION'] = m.receivingStation.cdata\n",
        "#  p['PROCESSING_STATION'] = m.processingStation.cdata\n",
        "#  p['PROCESSING_TIME'] = m.processingTime.cdata\n",
        "#  p['LEVEL'] = m.level.cdata\n",
        "#  p['COLUMNS'] = m.columns.cdata\n",
        "#  p['LINES'] = m.lines.cdata\n",
        "#  p['VERTICAL_PIXEL_SIZE'] = m.verticalPixelSize.cdata\n",
        "#  p['HORIZONTAL_PIXEL_SIZE'] = m.horizontalPixelSize.cdata\n",
        "#  p['ORBIT_DIRECTION'] = m.orbitDirection.cdata\n",
        "#  p['PATH'] = m.path.cdata\n",
        "#  p['ROW'] = m.row.cdata\n",
        "#  p['SUN_POSITION_ELEVATION'] = m.sunPosition.elevation.cdata\n",
        "#  p['SUN_POSITION_AZIMUTH'] = m.sunPosition.sunAzimuth.cdata\n",
        "\n",
        "  return {'properties' : p,\n",
        "          'startTime': m.timeStamp.begin.cdata + \"Z\",\n",
        "          'endTime': m.timeStamp.end.cdata + \"Z\"\n",
        "          }\n",
        "\n",
        "def createIngestRequest(xml_url):\n",
        "  \"\"\"Given a URL to an XML file, build the request to register the image.\"\"\"\n",
        "  parsed = urlparse(xml_url)\n",
        "  path = pathlib.Path(parsed.path)\n",
        "\n",
        "  asset_id = path.parent.name\n",
        "  band_nums = [5, 6, 7, 8]\n",
        "  uri_prefix = urlunparse([parsed.scheme, parsed.netloc, str(path.parent) + '/', '', '', ''])\n",
        "  tilesets = list(map(lambda band_num: {\n",
        "          \"id\": str(band_num),\n",
        "          \"sources\": {\n",
        "            \"uris\": [ str(path.name).replace('BAND14.xml', f'BAND{band_num}.tif') ]\n",
        "          }\n",
        "      }, band_nums))\n",
        "  bands = list(map(lambda band_num: {\n",
        "      \"id\": f\"B{band_num}\",\n",
        "      \"tilesetId\": str(band_num)\n",
        "  }, band_nums))\n",
        "\n",
        "  return {\n",
        "     \"imageManifest\": {\n",
        "        \"name\": f\"projects/{ee_project}/assets/CBERS4A/WFI/{asset_id}\",\n",
        "        \"uriPrefix\": uri_prefix,\n",
        "        \"tilesets\": tilesets,\n",
        "        \"bands\": bands,\n",
        "        **getMetadata(xml_url)\n",
        "      },\n",
        "      \"overwrite\": True\n",
        "  }"
      ],
      "metadata": {
        "id": "GpkdZNsJPT2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "\n",
        "failedImages = []\n",
        "\n",
        "def importImage(xmlUrl):\n",
        "  \"\"\"Import the image.\"\"\"\n",
        "  try:\n",
        "    request = createIngestRequest(xmlUrl)\n",
        "    url = f\"https://earthengine.googleapis.com/v1alpha/projects/{ee_project}/image:importExternal\"\n",
        "    data = json.dumps(request)\n",
        "    fetchWithBackoff(url, data)\n",
        "  except Exception as ex:\n",
        "    failedImages.append(f\"{xmlUrl} {ex}\")\n",
        "\n",
        "def fetchWithBackoff(url, data, max_retries=5):\n",
        "  \"\"\"Post data to the given URL, retrying if necessary.\"\"\"\n",
        "    retry_delay = 1  # Initial delay in seconds\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = session.post(\n",
        "              url=url,\n",
        "              data=data,\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.RequestException:\n",
        "          time.sleep(retry_delay)\n",
        "          retry_delay *= 2\n",
        "          retry_delay += random.uniform(0, 1)\n",
        "    raise Exception(f\"Maximum retries hit\\n{data}\\n Final response: {response.reason}\")\n",
        "\n",
        "\n",
        "# Actually register all of the images that correspond to the XML files in the\n",
        "# list of URLs.\n",
        "with open('xmlfiles.txt') as f:\n",
        "  warnings.filterwarnings('ignore', message=\".*Connection pool size.*\")\n",
        "  lines = list(f.readlines())\n",
        "  with ThreadPoolExecutor(max_workers=THREAD_COUNT) as pool:\n",
        "    print(\"Running...\")\n",
        "    list(tqdm(pool.map(importImage, lines), total=len(lines)))\n",
        "print(f'Done. Failed images: {failed_images}')"
      ],
      "metadata": {
        "id": "oEFnFIxPRpie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}